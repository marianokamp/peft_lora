{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b77769d5-585f-44a6-93ef-4e1582732e39",
   "metadata": {},
   "source": [
    "# Deploying LoRA tuned models - Multitask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6bac5451-bc46-4e8b-b5ed-9c738ddee993",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sun Mar 31 22:18:30 CEST 2024\n"
     ]
    }
   ],
   "source": [
    "!date"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "cbc21e95-bc88-4180-ab3e-e6c345612745",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/Users/mkamp/code/peft_lora\n"
     ]
    }
   ],
   "source": [
    "!pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f270784f-ad25-443c-80fa-6f72ac6bedde",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#!pip install -Uq -r src/requirements.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "34dd2ff2-e379-4157-aafb-a44593343310",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "9cc7e498-bbae-4a52-b633-1d1908597990",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('src')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "009e9af2-11e2-49b2-9263-0b07e63e3201",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sagemaker.config INFO - Not applying SDK defaults from location: /Library/Preferences/sagemaker/config.yaml\n",
      "sagemaker.config INFO - Not applying SDK defaults from location: /Users/mkamp/Library/Preferences/sagemaker/config.yaml\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of RobertaForSequenceClassification were not initialized from the model checkpoint at roberta-base and are newly initialized: ['classifier.dense.bias', 'classifier.dense.weight', 'classifier.out_proj.bias', 'classifier.out_proj.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:util:Total parameters: 124,647,170, thereof learnable: 124,647,170 (100.0000%)\n"
     ]
    }
   ],
   "source": [
    "from sagemaker.pytorch import PyTorch\n",
    "\n",
    "import pandas as pd\n",
    "import altair as alt\n",
    "import time\n",
    "\n",
    "import boto3\n",
    "from nb_helper import *\n",
    "sm = boto3.client('sagemaker')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "b0646a45-c75f-4236-b146-314db1c90c26",
   "metadata": {},
   "outputs": [],
   "source": [
    "# One run with sst2,\n",
    "# one training with sst2 LoRA, cola LoRA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "0445cec6-55df-43a5-9d3f-5ec017515d43",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'entry_point': 'train.py',\n",
       " 'source_dir': 'src',\n",
       " 'instance_type': 'ml.g5.xlarge',\n",
       " 'instance_count': 1,\n",
       " 'framework_version': '2.1',\n",
       " 'py_version': 'py310',\n",
       " 'base_job_name': 'lora',\n",
       " 'use_spot_instances': True,\n",
       " 'max_run': 68640,\n",
       " 'max_wait': 68640,\n",
       " 'role': 'arn:aws:iam::753739741425:role/admin',\n",
       " 'metric_definitions': [{'Name': 'learning_rate',\n",
       "   'Regex': \"\\\\'learning_rate\\\\': (-?[0-9\\\\.e-]+)\"},\n",
       "  {'Name': 'train_epoch_duration', 'Regex': 'Epoch duration: (-?[0-9\\\\.]+)s'},\n",
       "  {'Name': 'gpu_memory', 'Regex': 'GPU Usage.*?\\\\(([0-9\\\\.]+)% used\\\\)'},\n",
       "  {'Name': 'train_samples_sec',\n",
       "   'Regex': \"\\\\'train_samples_per_second\\\\': (-?[0-9\\\\.]+)\"},\n",
       "  {'Name': 'valid_f1', 'Regex': \"\\\\'eval_f1\\\\': (-?[0-9\\\\.]+)\"},\n",
       "  {'Name': 'sst2_valid_matthews_correlation',\n",
       "   'Regex': \"\\\\'eval_sst2_matthews_correlation\\\\': (-?[0-9\\\\.]+)\"},\n",
       "  {'Name': 'cola_valid_matthews_correlation',\n",
       "   'Regex': \"\\\\'eval_cola_matthews_correlation\\\\': (-?[0-9\\\\.]+)\"},\n",
       "  {'Name': 'sst2_valid_f1', 'Regex': \"\\\\'eval_sst2_f1\\\\': (-?[0-9\\\\.]+)\"},\n",
       "  {'Name': 'cola_valid_f1', 'Regex': \"\\\\'eval_cola_f1\\\\': (-?[0-9\\\\.]+)\"},\n",
       "  {'Name': 'sst2_valid_acc',\n",
       "   'Regex': \"\\\\'eval_sst2_accuracy\\\\': (-?[0-9\\\\.]+)\"},\n",
       "  {'Name': 'cola_valid_acc',\n",
       "   'Regex': \"\\\\'eval_cola_accuracy\\\\': (-?[0-9\\\\.]+)\"},\n",
       "  {'Name': 'valid_loss', 'Regex': \"\\\\'eval_loss\\\\': (-?[0-9\\\\.]+)\"},\n",
       "  {'Name': 'train_loss', 'Regex': \"\\\\'loss\\\\': (-?[0-9\\\\.]+)\"},\n",
       "  {'Name': 'epoch', 'Regex': \"\\\\'epoch\\\\': (-?[0-9\\\\.]+)\"},\n",
       "  {'Name': 'eval_runtime', 'Regex': \"\\\\'eval_runtime\\\\': (-?[0-9\\\\.]+)\"},\n",
       "  {'Name': 'total_parameters', 'Regex': 'total_parameters: (-?[0-9\\\\.]+)'},\n",
       "  {'Name': 'learnable_parameters',\n",
       "   'Regex': 'learnable_parameters: (-?[0-9\\\\.]+)'},\n",
       "  {'Name': 'model_size_mb', 'Regex': 'Model size: (-?[0-9\\\\.]+) MB'}],\n",
       " 'hyperparameters': {'tasks': 'sst2',\n",
       "  'model-ckp': 'roberta-base',\n",
       "  'patience': 0,\n",
       "  'n-train-samples': 0,\n",
       "  'n-valid-samples': 0,\n",
       "  'n-warmup-steps': 0,\n",
       "  'warmup-ratio': 0.1,\n",
       "  'seed': 0,\n",
       "  'use-bf16': 1,\n",
       "  'clf-dropout': 0.05,\n",
       "  'hidden-dropout': 0.2,\n",
       "  'attention-dropout': 0.2,\n",
       "  'adam_beta1': 0.9,\n",
       "  'adam_beta2': 0.98,\n",
       "  'sst2-epochs': 10,\n",
       "  'sst2-lora-config': 'all',\n",
       "  'sst2-lora-dropout': 0.1,\n",
       "  'sst2-batch-size': 480,\n",
       "  'sst2-learning-rate': 0.0001,\n",
       "  'sst2-weight-decay': 0.01,\n",
       "  'cola-epochs': 10,\n",
       "  'cola-lora-config': 'all',\n",
       "  'cola-lora-dropout': 0.05,\n",
       "  'cola-batch-size': 224,\n",
       "  'cola-learning-rate': 0.00085,\n",
       "  'cola-weight-decay': 1e-09,\n",
       "  'use-gradient-checkpointing': 0}}"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_default_estimator_parameters()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "3da7ed1b-9ee6-41fa-bea8-837c5755b251",
   "metadata": {},
   "outputs": [],
   "source": [
    "sst2_fullft_estimator = PyTorch(**get_default_estimator_parameters())\n",
    "sst2_fullft_estimator.set_hyperparameters(**{\n",
    "    'n-warmup-steps':     5, \n",
    "    'seed':               42, \n",
    "    'tasks':              'sst2',\n",
    "    \n",
    "    'sst2-lora-config':   'none', \n",
    "    'sst2-batch-size':   192, # 480\n",
    "    'sst2-learning-rate': 5.3e-5,\n",
    "    'sst2-weight-decay':  0.1\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "3336157f-7e36-410f-8a0c-35af02016fb7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'tasks': '\"\\\\\"sst2\\\\\"\"',\n",
       " 'model-ckp': '\"roberta-base\"',\n",
       " 'patience': '0',\n",
       " 'n-train-samples': '0',\n",
       " 'n-valid-samples': '0',\n",
       " 'n-warmup-steps': '\"5\"',\n",
       " 'warmup-ratio': '0.1',\n",
       " 'seed': '\"42\"',\n",
       " 'use-bf16': '1',\n",
       " 'clf-dropout': '0.05',\n",
       " 'hidden-dropout': '0.2',\n",
       " 'attention-dropout': '0.2',\n",
       " 'adam_beta1': '0.9',\n",
       " 'adam_beta2': '0.98',\n",
       " 'sst2-epochs': '10',\n",
       " 'sst2-lora-config': '\"\\\\\"none\\\\\"\"',\n",
       " 'sst2-lora-dropout': '0.1',\n",
       " 'sst2-batch-size': '\"192\"',\n",
       " 'sst2-learning-rate': '\"5.3e-05\"',\n",
       " 'sst2-weight-decay': '\"0.1\"',\n",
       " 'cola-epochs': '10',\n",
       " 'cola-lora-config': '\"all\"',\n",
       " 'cola-lora-dropout': '0.05',\n",
       " 'cola-batch-size': '224',\n",
       " 'cola-learning-rate': '0.00085',\n",
       " 'cola-weight-decay': '1e-09',\n",
       " 'use-gradient-checkpointing': '0'}"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sst2_fullft_estimator.hyperparameters()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "a052104f-a609-47e2-b225-6b4f713194a5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:sagemaker.image_uris:image_uri is not presented, retrieving image_uri based on instance_type, framework etc.\n",
      "INFO:sagemaker:Creating training-job with name: lora-2024-03-31-20-18-38-053\n"
     ]
    }
   ],
   "source": [
    "sst2_fullft_estimator.fit(wait=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "00f98b93-1586-4855-ab80-abdd593371fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "sst2_cola_lora_estimator = PyTorch(**get_default_estimator_parameters())\n",
    "sst2_cola_lora_estimator.set_hyperparameters(**{\n",
    "\n",
    "    'n-warmup-steps':     5, \n",
    "    'seed':               42, \n",
    "    'tasks':              'sst2,cola',\n",
    "    \n",
    "    'sst2-lora-config':   'ff_u', \n",
    "    'sst2-lora-r':        4,\n",
    "    'sst2-batch-size':    224, # 480\n",
    "    'sst2-learning-rate': 2.3e-4,\n",
    "    'sst2-weight-decay':  0.1,\n",
    "    'sst2-lora-dropout':  0.15,\n",
    "    \n",
    "    'cola-lora-config':   'ff_u', \n",
    "    'cola-lora-r':        4,\n",
    "    'cola-batch-size':    384, # 224 \n",
    "    'cola-learning-rate': 9e-4,\n",
    "    'cola-weight-decay':  0.3,\n",
    "    'cola-lora-dropout':  0.3,\n",
    "    \n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "ccde7697-fb94-4344-9150-aa7e6a86bc4b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'tasks': '\"\\\\\"sst2,cola\\\\\"\"',\n",
       " 'model-ckp': '\"roberta-base\"',\n",
       " 'patience': '0',\n",
       " 'n-train-samples': '0',\n",
       " 'n-valid-samples': '0',\n",
       " 'n-warmup-steps': '\"5\"',\n",
       " 'warmup-ratio': '0.1',\n",
       " 'seed': '\"42\"',\n",
       " 'use-bf16': '1',\n",
       " 'clf-dropout': '0.05',\n",
       " 'hidden-dropout': '0.2',\n",
       " 'attention-dropout': '0.2',\n",
       " 'adam_beta1': '0.9',\n",
       " 'adam_beta2': '0.98',\n",
       " 'sst2-epochs': '10',\n",
       " 'sst2-lora-config': '\"\\\\\"ff_u\\\\\"\"',\n",
       " 'sst2-lora-dropout': '\"0.15\"',\n",
       " 'sst2-batch-size': '\"224\"',\n",
       " 'sst2-learning-rate': '\"0.00023\"',\n",
       " 'sst2-weight-decay': '\"0.1\"',\n",
       " 'cola-epochs': '10',\n",
       " 'cola-lora-config': '\"\\\\\"ff_u\\\\\"\"',\n",
       " 'cola-lora-dropout': '\"0.3\"',\n",
       " 'cola-batch-size': '\"384\"',\n",
       " 'cola-learning-rate': '\"0.0009\"',\n",
       " 'cola-weight-decay': '\"0.3\"',\n",
       " 'use-gradient-checkpointing': '0',\n",
       " 'sst2-lora-r': '\"4\"',\n",
       " 'cola-lora-r': '\"4\"'}"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sst2_cola_lora_estimator.hyperparameters()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "2778bb22-9729-45db-b243-fd792e1e18f1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:sagemaker.image_uris:image_uri is not presented, retrieving image_uri based on instance_type, framework etc.\n",
      "INFO:sagemaker:Creating training-job with name: lora-2024-03-31-20-18-40-603\n"
     ]
    }
   ],
   "source": [
    "sst2_cola_lora_estimator.fit(wait=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "95ebf961-7a8a-43cc-a7cf-8aa3b45497f9",
   "metadata": {},
   "source": [
    "### Prepare Inference (Tokenizer / Data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "4c28aa5b-f8e9-457b-96c0-be570a4c8bfd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:datasets:PyTorch version 2.2.2 available.\n",
      "'NoneType' object has no attribute 'cadam32bit_grad_fp32'\n",
      "INFO:train:torch version: 2.2.2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of RobertaForSequenceClassification were not initialized from the model checkpoint at roberta-base and are newly initialized: ['classifier.dense.bias', 'classifier.dense.weight', 'classifier.out_proj.bias', 'classifier.out_proj.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "from util import evaluate_tasks\n",
    "from train import tasks, prepare_data, load_model_and_tokenizer_and_collator\n",
    "_, tokenizer , _   = load_model_and_tokenizer_and_collator('roberta-base')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ad3ec5b-1f60-4b28-a13d-fb1694177d41",
   "metadata": {},
   "source": [
    "#### Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "7150ff15-eba6-40e7-8338-156d31127ba4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:train:Preparing data for task: sst2\n",
      "INFO:train:lapd called with n_train: None, n_valid: None\n",
      "INFO:train:Average train input length: 14.36\n",
      "INFO:train:Not randomizing order in input sequence.\n",
      "INFO:train:Preparing data for task: cola\n",
      "INFO:train:lapd called with n_train: None, n_valid: None\n",
      "INFO:train:Average train input length: 11.37\n",
      "INFO:train:Not randomizing order in input sequence.\n",
      "INFO:train:Preparing data for task: sst2\n",
      "INFO:train:lapd called with n_train: None, n_valid: None\n",
      "INFO:train:Average train input length: 14.36\n",
      "INFO:train:Preparing data for task: cola\n",
      "INFO:train:lapd called with n_train: None, n_valid: None\n",
      "INFO:train:Average train input length: 11.37\n",
      "INFO:train:Not randomizing order in input sequence.\n"
     ]
    }
   ],
   "source": [
    "sst2_data      = prepare_data(['sst2'], tokenizer)\n",
    "cola_data      = prepare_data(['cola'], tokenizer)\n",
    "sst2_cola_data = prepare_data(['sst2', 'cola'], tokenizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "6df0ff26-67d7-4eae-b548-7e9c183a9ce5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('sst2', 1, \"it 's a charming and often affecting journey . \"),\n",
       " ('sst2', 0, 'unflinchingly bleak and desperate ')]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sst2_data[:2]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc20f476-9168-418f-8cc6-ed3988f6f1c1",
   "metadata": {},
   "source": [
    "#### Deploying SST2 Endpoint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "2d8aea97-7a0a-4b2a-a3f4-9d1a73245df7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_job_metric(job, metric_names=None):\n",
    "    if isinstance(metric_names, str):\n",
    "        metrics = [metric_names]\n",
    "        \n",
    "    final_metrics = sm.describe_training_job(\n",
    "        TrainingJobName=sst2_fullft_estimator.latest_training_job.job_name)['FinalMetricDataList']\n",
    "    return [{fm['MetricName']: fm['Value']} for fm in final_metrics if metric_names is None or (fm['MetricName'] in metric_names)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "d3bd1537-9382-4773-ab65-43f42f6667d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "sm.get_waiter('training_job_completed_or_stopped').wait(TrainingJobName=sst2_fullft_estimator.latest_training_job.job_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "b21d9c04-08d7-4945-b85f-84497cdacb75",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'sst2_valid_acc': 0.9392201900482178}]"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_job_metric(sst2_fullft_estimator.latest_training_job.job_name, 'sst2_valid_acc')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "48614deb-7f2d-406a-be86-74658d892ffb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:sagemaker:Repacking model artifact (s3://sagemaker-eu-west-1-753739741425/lora-2024-03-31-20-18-38-053/output/model.tar.gz), script artifact (s3://sagemaker-eu-west-1-753739741425/lora-2024-03-31-20-18-38-053/source/sourcedir.tar.gz), and dependencies ([]) into single tar.gz file located at s3://sagemaker-eu-west-1-753739741425/lora-2024-03-31-20-39-04-572/model.tar.gz. This may take some time depending on model size...\n",
      "INFO:sagemaker:Creating model with name: lora-2024-03-31-20-39-04-572\n",
      "INFO:sagemaker:Creating endpoint-config with name lora-2024-03-31-20-39-04-572\n",
      "INFO:sagemaker:Creating endpoint with name lora-2024-03-31-20-39-04-572\n",
      "--------!CPU times: user 1min 31s, sys: 14.1 s, total: 1min 45s\n",
      "Wall time: 7min 58s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "sst2_predictor = sst2_fullft_estimator.deploy(initial_instance_count=1, instance_type='ml.g4dn.xlarge') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "9fa564ce-108e-46e5-a08d-81fdaa67bb4c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_standalone(inputs, tasks, bs=8):\n",
    "    request = {\n",
    "        'inputs': inputs, \n",
    "        'tasks': tasks, \n",
    "        'parameters': {'batch-size': bs}}\n",
    "    return sst2_predictor.predict(request)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "4cc66f9b-3ff7-4e3f-9c93-ba6241f54026",
   "metadata": {},
   "outputs": [],
   "source": [
    "k = 7\n",
    "measurements = []\n",
    "def measure(name, f):\n",
    "    for i in range(k):\n",
    "        started = time.time()\n",
    "        f()\n",
    "        duration = time.time() - started\n",
    "        measurements.append((name, duration))\n",
    "        print(f'Measured {name} {duration:7.6f}s.')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f704ebe8-2233-4025-801b-e33ed393fda1",
   "metadata": {},
   "source": [
    "#### Executing Inference SST2 Standalone"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "f5317632-d44f-4a2c-a0df-e451b509fd34",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ".     correct      task prediction   y\n",
      "        mean sum count        sum sum\n",
      "task                                 \n",
      "sst2     1.0  10    10          5   5\n",
      "Overall acc: 1.0\n",
      "CPU times: user 28.1 ms, sys: 9.93 ms, total: 38 ms\n",
      "Wall time: 2.52 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# Warmup with 10 records\n",
    "_ = evaluate_tasks(predict_standalone, sst2_data[:10], inner_bs=10, task_aware=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "802d4dd6-5971-4c26-9add-73ddc286b9fc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "....      correct       task prediction    y\n",
      "         mean  sum count        sum  sum\n",
      "task                                    \n",
      "sst2  0.93922  819   872        455  444\n",
      "Overall acc: 0.9392201834862385\n",
      "Measured Standalone SST-2 2.361973s.\n",
      "....      correct       task prediction    y\n",
      "         mean  sum count        sum  sum\n",
      "task                                    \n",
      "sst2  0.93922  819   872        455  444\n",
      "Overall acc: 0.9392201834862385\n",
      "Measured Standalone SST-2 2.331867s.\n",
      "....      correct       task prediction    y\n",
      "         mean  sum count        sum  sum\n",
      "task                                    \n",
      "sst2  0.93922  819   872        455  444\n",
      "Overall acc: 0.9392201834862385\n",
      "Measured Standalone SST-2 2.349175s.\n",
      "....      correct       task prediction    y\n",
      "         mean  sum count        sum  sum\n",
      "task                                    \n",
      "sst2  0.93922  819   872        455  444\n",
      "Overall acc: 0.9392201834862385\n",
      "Measured Standalone SST-2 2.353385s.\n",
      "....      correct       task prediction    y\n",
      "         mean  sum count        sum  sum\n",
      "task                                    \n",
      "sst2  0.93922  819   872        455  444\n",
      "Overall acc: 0.9392201834862385\n",
      "Measured Standalone SST-2 2.367928s.\n",
      "....      correct       task prediction    y\n",
      "         mean  sum count        sum  sum\n",
      "task                                    \n",
      "sst2  0.93922  819   872        455  444\n",
      "Overall acc: 0.9392201834862385\n",
      "Measured Standalone SST-2 2.337843s.\n",
      "....      correct       task prediction    y\n",
      "         mean  sum count        sum  sum\n",
      "task                                    \n",
      "sst2  0.93922  819   872        455  444\n",
      "Overall acc: 0.9392201834862385\n",
      "Measured Standalone SST-2 2.348287s.\n"
     ]
    }
   ],
   "source": [
    "measure('Standalone SST-2', lambda: evaluate_tasks(predict_standalone, sst2_data, outer_bs=256, inner_bs=256, task_aware=False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "e5601559-4b21-4b60-b2ee-78eba812a921",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:sagemaker:Deleting model with name: lora-2024-03-31-20-39-04-572\n",
      "INFO:sagemaker:Deleting endpoint configuration with name: lora-2024-03-31-20-39-04-572\n",
      "INFO:sagemaker:Deleting endpoint with name: lora-2024-03-31-20-39-04-572\n"
     ]
    }
   ],
   "source": [
    "sst2_predictor.delete_model()\n",
    "sst2_predictor.delete_endpoint()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c78ba68e-2d72-4289-b6b2-c708b1faa198",
   "metadata": {},
   "source": [
    "#### Deploying Multi-Task Endpoints"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "d2727615-f7fe-48d5-b305-29dcb6d282c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "sm.get_waiter('training_job_completed_or_stopped').wait(TrainingJobName=sst2_cola_lora_estimator.latest_training_job.job_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "8c0ff331-d104-4ff6-ac81-dcf5b01be6cd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'sst2_valid_acc': 0.9392201900482178}]"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_job_metric(sst2_cola_lora_estimator.latest_training_job.job_name, ['sst2_valid_acc', 'cola_valid_acc'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "cd295a92-0758-40f4-b86d-acce79e7b0aa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:sagemaker:Repacking model artifact (s3://sagemaker-eu-west-1-753739741425/lora-2024-03-31-20-18-40-603/output/model.tar.gz), script artifact (s3://sagemaker-eu-west-1-753739741425/lora-2024-03-31-20-18-40-603/source/sourcedir.tar.gz), and dependencies ([]) into single tar.gz file located at s3://sagemaker-eu-west-1-753739741425/lora-2024-03-31-20-47-23-961/model.tar.gz. This may take some time depending on model size...\n",
      "INFO:sagemaker:Creating model with name: lora-2024-03-31-20-47-23-961\n",
      "INFO:sagemaker:Creating endpoint-config with name lora-2024-03-31-20-47-23-961\n",
      "INFO:sagemaker:Creating endpoint with name lora-2024-03-31-20-47-23-961\n",
      "--------!CPU times: user 3min 50s, sys: 5.76 s, total: 3min 55s\n",
      "Wall time: 9min\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "sst2_cola_lora_predictor = sst2_cola_lora_estimator.deploy(initial_instance_count=1, instance_type='ml.g4dn.xlarge')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "842f206c-0424-48f6-9580-b4232d0cb9a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict(inputs, tasks, bs):\n",
    "    request = {\n",
    "        'inputs': inputs, \n",
    "        'tasks': tasks,\n",
    "        'parameters': {'batch-size': bs}\n",
    "    } \n",
    "    return sst2_cola_lora_predictor.predict(request)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "773b6b06-12cd-43e1-a5ce-22cf03dec3e9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ".     correct      task prediction   y\n",
      "        mean sum count        sum sum\n",
      "task                                 \n",
      "sst2     1.0  10    10          5   5\n",
      "Overall acc: 1.0\n",
      "CPU times: user 30.7 ms, sys: 5.98 ms, total: 36.6 ms\n",
      "Wall time: 787 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# Warmup with 10 records\n",
    "_ = evaluate_tasks(predict, sst2_data[:10], inner_bs=128);"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "98ac9f11-b3eb-4ddc-8f6c-6ad36f466c5e",
   "metadata": {},
   "source": [
    "# Now running inference in task aware mode on the LoRA trained task head for SST-2."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "84670ae6-9970-4584-8e4d-3a3519b492b7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "....       correct       task prediction    y\n",
      "          mean  sum count        sum  sum\n",
      "task                                     \n",
      "sst2  0.941514  821   872        453  444\n",
      "Overall acc: 0.9415137614678899\n",
      "Measured SST-2 LoRA 2.340473s.\n",
      "....       correct       task prediction    y\n",
      "          mean  sum count        sum  sum\n",
      "task                                     \n",
      "sst2  0.941514  821   872        453  444\n",
      "Overall acc: 0.9415137614678899\n",
      "Measured SST-2 LoRA 2.306693s.\n",
      "....       correct       task prediction    y\n",
      "          mean  sum count        sum  sum\n",
      "task                                     \n",
      "sst2  0.941514  821   872        453  444\n",
      "Overall acc: 0.9415137614678899\n",
      "Measured SST-2 LoRA 2.307383s.\n",
      "....       correct       task prediction    y\n",
      "          mean  sum count        sum  sum\n",
      "task                                     \n",
      "sst2  0.941514  821   872        453  444\n",
      "Overall acc: 0.9415137614678899\n",
      "Measured SST-2 LoRA 2.307755s.\n",
      "....       correct       task prediction    y\n",
      "          mean  sum count        sum  sum\n",
      "task                                     \n",
      "sst2  0.941514  821   872        453  444\n",
      "Overall acc: 0.9415137614678899\n",
      "Measured SST-2 LoRA 2.311699s.\n",
      "....       correct       task prediction    y\n",
      "          mean  sum count        sum  sum\n",
      "task                                     \n",
      "sst2  0.941514  821   872        453  444\n",
      "Overall acc: 0.9415137614678899\n",
      "Measured SST-2 LoRA 2.275882s.\n",
      "....       correct       task prediction    y\n",
      "          mean  sum count        sum  sum\n",
      "task                                     \n",
      "sst2  0.941514  821   872        453  444\n",
      "Overall acc: 0.9415137614678899\n",
      "Measured SST-2 LoRA 2.291002s.\n"
     ]
    }
   ],
   "source": [
    "measure('SST-2 LoRA', lambda: evaluate_tasks(predict, sst2_data, inner_bs=256))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "46d1a323-2b17-4efd-8053-d8d7587b3cdb",
   "metadata": {},
   "source": [
    "# Now running inference in task aware mode on the LoRA trained task head for CoLA."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "17731677-44d0-44c6-9327-8dcc353e7774",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ".....       correct       task prediction    y\n",
      "          mean  sum count        sum  sum\n",
      "task                                     \n",
      "cola  0.785235  819  1043        893  721\n",
      "Overall acc: 0.785234899328859\n",
      "Measured CoLA LoRA 1.567847s.\n",
      ".....       correct       task prediction    y\n",
      "          mean  sum count        sum  sum\n",
      "task                                     \n",
      "cola  0.785235  819  1043        893  721\n",
      "Overall acc: 0.785234899328859\n",
      "Measured CoLA LoRA 1.568452s.\n",
      ".....       correct       task prediction    y\n",
      "          mean  sum count        sum  sum\n",
      "task                                     \n",
      "cola  0.785235  819  1043        893  721\n",
      "Overall acc: 0.785234899328859\n",
      "Measured CoLA LoRA 1.566868s.\n",
      ".....       correct       task prediction    y\n",
      "          mean  sum count        sum  sum\n",
      "task                                     \n",
      "cola  0.785235  819  1043        893  721\n",
      "Overall acc: 0.785234899328859\n",
      "Measured CoLA LoRA 1.553799s.\n",
      ".....       correct       task prediction    y\n",
      "          mean  sum count        sum  sum\n",
      "task                                     \n",
      "cola  0.785235  819  1043        893  721\n",
      "Overall acc: 0.785234899328859\n",
      "Measured CoLA LoRA 1.554144s.\n",
      ".....       correct       task prediction    y\n",
      "          mean  sum count        sum  sum\n",
      "task                                     \n",
      "cola  0.785235  819  1043        893  721\n",
      "Overall acc: 0.785234899328859\n",
      "Measured CoLA LoRA 1.555887s.\n",
      ".....       correct       task prediction    y\n",
      "          mean  sum count        sum  sum\n",
      "task                                     \n",
      "cola  0.785235  819  1043        893  721\n",
      "Overall acc: 0.785234899328859\n",
      "Measured CoLA LoRA 1.536167s.\n"
     ]
    }
   ],
   "source": [
    "measure('CoLA LoRA', lambda: evaluate_tasks(predict, cola_data, inner_bs=256))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "1a472ec6-2e27-4d24-8fa1-cc3f20438d62",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "........       correct       task prediction    y\n",
      "          mean  sum count        sum  sum\n",
      "task                                     \n",
      "cola  0.785235  819  1043        893  721\n",
      "sst2  0.941514  821   872        453  444\n",
      "Overall acc: 0.856396866840731\n",
      "Measured CoLA and SST-2 LoRA 3.809797s.\n",
      "........       correct       task prediction    y\n",
      "          mean  sum count        sum  sum\n",
      "task                                     \n",
      "cola  0.785235  819  1043        893  721\n",
      "sst2  0.941514  821   872        453  444\n",
      "Overall acc: 0.856396866840731\n",
      "Measured CoLA and SST-2 LoRA 3.798334s.\n",
      "........       correct       task prediction    y\n",
      "          mean  sum count        sum  sum\n",
      "task                                     \n",
      "cola  0.785235  819  1043        893  721\n",
      "sst2  0.941514  821   872        453  444\n",
      "Overall acc: 0.856396866840731\n",
      "Measured CoLA and SST-2 LoRA 3.798508s.\n",
      "........       correct       task prediction    y\n",
      "          mean  sum count        sum  sum\n",
      "task                                     \n",
      "cola  0.785235  819  1043        893  721\n",
      "sst2  0.941514  821   872        453  444\n",
      "Overall acc: 0.856396866840731\n",
      "Measured CoLA and SST-2 LoRA 3.807919s.\n",
      "........       correct       task prediction    y\n",
      "          mean  sum count        sum  sum\n",
      "task                                     \n",
      "cola  0.785235  819  1043        893  721\n",
      "sst2  0.941514  821   872        453  444\n",
      "Overall acc: 0.856396866840731\n",
      "Measured CoLA and SST-2 LoRA 3.807874s.\n",
      "........       correct       task prediction    y\n",
      "          mean  sum count        sum  sum\n",
      "task                                     \n",
      "cola  0.785235  819  1043        893  721\n",
      "sst2  0.941514  821   872        453  444\n",
      "Overall acc: 0.856396866840731\n",
      "Measured CoLA and SST-2 LoRA 3.801367s.\n",
      "........       correct       task prediction    y\n",
      "          mean  sum count        sum  sum\n",
      "task                                     \n",
      "cola  0.785235  819  1043        893  721\n",
      "sst2  0.941514  821   872        453  444\n",
      "Overall acc: 0.856396866840731\n",
      "Measured CoLA and SST-2 LoRA 3.836647s.\n"
     ]
    }
   ],
   "source": [
    "measure('CoLA and SST-2 LoRA', lambda: evaluate_tasks(predict, sst2_cola_data, outer_bs=256, inner_bs=256))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "418d23c5-bb46-4e41-9457-158d342f7fc7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "([('cola', 1, 'Kim is eager to please Tom.'),\n",
       "  ('sst2',\n",
       "   0,\n",
       "   'schaeffer has to find some hook on which to hang his persistently useless movies , and it might as well be the resuscitation of the middle-aged character . ')],\n",
       " [('sst2', 1, \"it 's a charming and often affecting journey . \"),\n",
       "  ('sst2', 0, 'unflinchingly bleak and desperate ')])"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import random\n",
    "shuffled_data = sst2_cola_data.copy()\n",
    "random.shuffle(shuffled_data)\n",
    "shuffled_data[:2], sst2_cola_data[:2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "b1412c2d-0188-4849-a417-8fc6798db4fa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "### req_size   64:\n",
      "..............................       correct       task prediction    y\n",
      "          mean  sum count        sum  sum\n",
      "task                                     \n",
      "cola  0.785235  819  1043        893  721\n",
      "sst2  0.941514  821   872        453  444\n",
      "Overall acc: 0.856396866840731\n",
      "Measured CoLA and SST-2 LoRA (Shuffled, req_size=64) 4.835491s.\n",
      "..............................       correct       task prediction    y\n",
      "          mean  sum count        sum  sum\n",
      "task                                     \n",
      "cola  0.785235  819  1043        893  721\n",
      "sst2  0.941514  821   872        453  444\n",
      "Overall acc: 0.856396866840731\n",
      "Measured CoLA and SST-2 LoRA (Shuffled, req_size=64) 4.827936s.\n",
      "..............................       correct       task prediction    y\n",
      "          mean  sum count        sum  sum\n",
      "task                                     \n",
      "cola  0.785235  819  1043        893  721\n",
      "sst2  0.941514  821   872        453  444\n",
      "Overall acc: 0.856396866840731\n",
      "Measured CoLA and SST-2 LoRA (Shuffled, req_size=64) 4.813034s.\n",
      "..............................       correct       task prediction    y\n",
      "          mean  sum count        sum  sum\n",
      "task                                     \n",
      "cola  0.785235  819  1043        893  721\n",
      "sst2  0.941514  821   872        453  444\n",
      "Overall acc: 0.856396866840731\n",
      "Measured CoLA and SST-2 LoRA (Shuffled, req_size=64) 4.798724s.\n",
      "..............................       correct       task prediction    y\n",
      "          mean  sum count        sum  sum\n",
      "task                                     \n",
      "cola  0.785235  819  1043        893  721\n",
      "sst2  0.941514  821   872        453  444\n",
      "Overall acc: 0.856396866840731\n",
      "Measured CoLA and SST-2 LoRA (Shuffled, req_size=64) 4.818588s.\n",
      "..............................       correct       task prediction    y\n",
      "          mean  sum count        sum  sum\n",
      "task                                     \n",
      "cola  0.785235  819  1043        893  721\n",
      "sst2  0.941514  821   872        453  444\n",
      "Overall acc: 0.856396866840731\n",
      "Measured CoLA and SST-2 LoRA (Shuffled, req_size=64) 4.824540s.\n",
      "..............................       correct       task prediction    y\n",
      "          mean  sum count        sum  sum\n",
      "task                                     \n",
      "cola  0.785235  819  1043        893  721\n",
      "sst2  0.941514  821   872        453  444\n",
      "Overall acc: 0.856396866840731\n",
      "Measured CoLA and SST-2 LoRA (Shuffled, req_size=64) 4.806060s.\n",
      "\n",
      "### req_size  256:\n",
      "........       correct       task prediction    y\n",
      "          mean  sum count        sum  sum\n",
      "task                                     \n",
      "cola  0.785235  819  1043        893  721\n",
      "sst2  0.941514  821   872        453  444\n",
      "Overall acc: 0.856396866840731\n",
      "Measured CoLA and SST-2 LoRA (Shuffled, req_size=256) 4.038430s.\n",
      "........       correct       task prediction    y\n",
      "          mean  sum count        sum  sum\n",
      "task                                     \n",
      "cola  0.785235  819  1043        893  721\n",
      "sst2  0.941514  821   872        453  444\n",
      "Overall acc: 0.856396866840731\n",
      "Measured CoLA and SST-2 LoRA (Shuffled, req_size=256) 4.036217s.\n",
      "........       correct       task prediction    y\n",
      "          mean  sum count        sum  sum\n",
      "task                                     \n",
      "cola  0.785235  819  1043        893  721\n",
      "sst2  0.941514  821   872        453  444\n",
      "Overall acc: 0.856396866840731\n",
      "Measured CoLA and SST-2 LoRA (Shuffled, req_size=256) 4.015429s.\n",
      "........       correct       task prediction    y\n",
      "          mean  sum count        sum  sum\n",
      "task                                     \n",
      "cola  0.785235  819  1043        893  721\n",
      "sst2  0.941514  821   872        453  444\n",
      "Overall acc: 0.856396866840731\n",
      "Measured CoLA and SST-2 LoRA (Shuffled, req_size=256) 4.029916s.\n",
      "........       correct       task prediction    y\n",
      "          mean  sum count        sum  sum\n",
      "task                                     \n",
      "cola  0.785235  819  1043        893  721\n",
      "sst2  0.941514  821   872        453  444\n",
      "Overall acc: 0.856396866840731\n",
      "Measured CoLA and SST-2 LoRA (Shuffled, req_size=256) 4.010116s.\n",
      "........       correct       task prediction    y\n",
      "          mean  sum count        sum  sum\n",
      "task                                     \n",
      "cola  0.785235  819  1043        893  721\n",
      "sst2  0.941514  821   872        453  444\n",
      "Overall acc: 0.856396866840731\n",
      "Measured CoLA and SST-2 LoRA (Shuffled, req_size=256) 4.030785s.\n",
      "........       correct       task prediction    y\n",
      "          mean  sum count        sum  sum\n",
      "task                                     \n",
      "cola  0.785235  819  1043        893  721\n",
      "sst2  0.941514  821   872        453  444\n",
      "Overall acc: 0.856396866840731\n",
      "Measured CoLA and SST-2 LoRA (Shuffled, req_size=256) 3.995776s.\n",
      "\n",
      "### req_size  512:\n",
      "....       correct       task prediction    y\n",
      "          mean  sum count        sum  sum\n",
      "task                                     \n",
      "cola  0.785235  819  1043        893  721\n",
      "sst2  0.941514  821   872        453  444\n",
      "Overall acc: 0.856396866840731\n",
      "Measured CoLA and SST-2 LoRA (Shuffled, req_size=512) 4.184632s.\n",
      "....       correct       task prediction    y\n",
      "          mean  sum count        sum  sum\n",
      "task                                     \n",
      "cola  0.785235  819  1043        893  721\n",
      "sst2  0.941514  821   872        453  444\n",
      "Overall acc: 0.856396866840731\n",
      "Measured CoLA and SST-2 LoRA (Shuffled, req_size=512) 4.053811s.\n",
      "....       correct       task prediction    y\n",
      "          mean  sum count        sum  sum\n",
      "task                                     \n",
      "cola  0.785235  819  1043        893  721\n",
      "sst2  0.941514  821   872        453  444\n",
      "Overall acc: 0.856396866840731\n",
      "Measured CoLA and SST-2 LoRA (Shuffled, req_size=512) 4.092608s.\n",
      "....       correct       task prediction    y\n",
      "          mean  sum count        sum  sum\n",
      "task                                     \n",
      "cola  0.785235  819  1043        893  721\n",
      "sst2  0.941514  821   872        453  444\n",
      "Overall acc: 0.856396866840731\n",
      "Measured CoLA and SST-2 LoRA (Shuffled, req_size=512) 4.058788s.\n",
      "....       correct       task prediction    y\n",
      "          mean  sum count        sum  sum\n",
      "task                                     \n",
      "cola  0.785235  819  1043        893  721\n",
      "sst2  0.941514  821   872        453  444\n",
      "Overall acc: 0.856396866840731\n",
      "Measured CoLA and SST-2 LoRA (Shuffled, req_size=512) 4.068758s.\n",
      "....       correct       task prediction    y\n",
      "          mean  sum count        sum  sum\n",
      "task                                     \n",
      "cola  0.785235  819  1043        893  721\n",
      "sst2  0.941514  821   872        453  444\n",
      "Overall acc: 0.856396866840731\n",
      "Measured CoLA and SST-2 LoRA (Shuffled, req_size=512) 4.054235s.\n",
      "....       correct       task prediction    y\n",
      "          mean  sum count        sum  sum\n",
      "task                                     \n",
      "cola  0.785235  819  1043        893  721\n",
      "sst2  0.941514  821   872        453  444\n",
      "Overall acc: 0.856396866840731\n",
      "Measured CoLA and SST-2 LoRA (Shuffled, req_size=512) 4.077520s.\n",
      "\n",
      "### req_size 1024:\n",
      "..       correct       task prediction    y\n",
      "          mean  sum count        sum  sum\n",
      "task                                     \n",
      "cola  0.785235  819  1043        893  721\n",
      "sst2  0.941514  821   872        453  444\n",
      "Overall acc: 0.856396866840731\n",
      "Measured CoLA and SST-2 LoRA (Shuffled, req_size=1024) 3.944459s.\n",
      "..       correct       task prediction    y\n",
      "          mean  sum count        sum  sum\n",
      "task                                     \n",
      "cola  0.785235  819  1043        893  721\n",
      "sst2  0.941514  821   872        453  444\n",
      "Overall acc: 0.856396866840731\n",
      "Measured CoLA and SST-2 LoRA (Shuffled, req_size=1024) 3.904110s.\n",
      "..       correct       task prediction    y\n",
      "          mean  sum count        sum  sum\n",
      "task                                     \n",
      "cola  0.785235  819  1043        893  721\n",
      "sst2  0.941514  821   872        453  444\n",
      "Overall acc: 0.856396866840731\n",
      "Measured CoLA and SST-2 LoRA (Shuffled, req_size=1024) 3.914973s.\n",
      "..       correct       task prediction    y\n",
      "          mean  sum count        sum  sum\n",
      "task                                     \n",
      "cola  0.785235  819  1043        893  721\n",
      "sst2  0.941514  821   872        453  444\n",
      "Overall acc: 0.856396866840731\n",
      "Measured CoLA and SST-2 LoRA (Shuffled, req_size=1024) 3.932122s.\n",
      "..       correct       task prediction    y\n",
      "          mean  sum count        sum  sum\n",
      "task                                     \n",
      "cola  0.785235  819  1043        893  721\n",
      "sst2  0.941514  821   872        453  444\n",
      "Overall acc: 0.856396866840731\n",
      "Measured CoLA and SST-2 LoRA (Shuffled, req_size=1024) 3.893598s.\n",
      "..       correct       task prediction    y\n",
      "          mean  sum count        sum  sum\n",
      "task                                     \n",
      "cola  0.785235  819  1043        893  721\n",
      "sst2  0.941514  821   872        453  444\n",
      "Overall acc: 0.856396866840731\n",
      "Measured CoLA and SST-2 LoRA (Shuffled, req_size=1024) 3.907622s.\n",
      "..       correct       task prediction    y\n",
      "          mean  sum count        sum  sum\n",
      "task                                     \n",
      "cola  0.785235  819  1043        893  721\n",
      "sst2  0.941514  821   872        453  444\n",
      "Overall acc: 0.856396866840731\n",
      "Measured CoLA and SST-2 LoRA (Shuffled, req_size=1024) 3.911135s.\n"
     ]
    }
   ],
   "source": [
    "for req_size in [64, 256, 512, 1024]:\n",
    "    print(f'\\n### req_size {req_size:4d}:')\n",
    "    measure(f'CoLA and SST-2 LoRA (Shuffled, req_size={req_size})',  lambda: evaluate_tasks(predict, shuffled_data, outer_bs=req_size, inner_bs=256))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "b1210904-419c-49fd-bbf3-e585987a68e8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('Standalone SST-2', 2.3619730472564697),\n",
       " ('Standalone SST-2', 2.331866979598999),\n",
       " ('Standalone SST-2', 2.349174976348877),\n",
       " ('Standalone SST-2', 2.3533852100372314),\n",
       " ('Standalone SST-2', 2.3679277896881104),\n",
       " ('Standalone SST-2', 2.3378429412841797),\n",
       " ('Standalone SST-2', 2.3482871055603027),\n",
       " ('SST-2 LoRA', 2.340473175048828),\n",
       " ('SST-2 LoRA', 2.3066933155059814),\n",
       " ('SST-2 LoRA', 2.3073830604553223),\n",
       " ('SST-2 LoRA', 2.3077549934387207),\n",
       " ('SST-2 LoRA', 2.311699390411377),\n",
       " ('SST-2 LoRA', 2.2758820056915283),\n",
       " ('SST-2 LoRA', 2.291001796722412),\n",
       " ('CoLA LoRA', 1.5678470134735107),\n",
       " ('CoLA LoRA', 1.5684518814086914),\n",
       " ('CoLA LoRA', 1.5668680667877197),\n",
       " ('CoLA LoRA', 1.5537991523742676),\n",
       " ('CoLA LoRA', 1.5541441440582275),\n",
       " ('CoLA LoRA', 1.555887222290039),\n",
       " ('CoLA LoRA', 1.5361671447753906),\n",
       " ('CoLA and SST-2 LoRA', 3.8097968101501465),\n",
       " ('CoLA and SST-2 LoRA', 3.7983341217041016),\n",
       " ('CoLA and SST-2 LoRA', 3.7985079288482666),\n",
       " ('CoLA and SST-2 LoRA', 3.8079190254211426),\n",
       " ('CoLA and SST-2 LoRA', 3.8078742027282715),\n",
       " ('CoLA and SST-2 LoRA', 3.8013670444488525),\n",
       " ('CoLA and SST-2 LoRA', 3.836646795272827),\n",
       " ('CoLA and SST-2 LoRA (Shuffled, req_size=64)', 4.835491180419922),\n",
       " ('CoLA and SST-2 LoRA (Shuffled, req_size=64)', 4.827936172485352),\n",
       " ('CoLA and SST-2 LoRA (Shuffled, req_size=64)', 4.813033819198608),\n",
       " ('CoLA and SST-2 LoRA (Shuffled, req_size=64)', 4.798723936080933),\n",
       " ('CoLA and SST-2 LoRA (Shuffled, req_size=64)', 4.818588018417358),\n",
       " ('CoLA and SST-2 LoRA (Shuffled, req_size=64)', 4.824540138244629),\n",
       " ('CoLA and SST-2 LoRA (Shuffled, req_size=64)', 4.806059837341309),\n",
       " ('CoLA and SST-2 LoRA (Shuffled, req_size=256)', 4.038430213928223),\n",
       " ('CoLA and SST-2 LoRA (Shuffled, req_size=256)', 4.036216735839844),\n",
       " ('CoLA and SST-2 LoRA (Shuffled, req_size=256)', 4.0154290199279785),\n",
       " ('CoLA and SST-2 LoRA (Shuffled, req_size=256)', 4.029916286468506),\n",
       " ('CoLA and SST-2 LoRA (Shuffled, req_size=256)', 4.0101158618927),\n",
       " ('CoLA and SST-2 LoRA (Shuffled, req_size=256)', 4.030784845352173),\n",
       " ('CoLA and SST-2 LoRA (Shuffled, req_size=256)', 3.9957761764526367),\n",
       " ('CoLA and SST-2 LoRA (Shuffled, req_size=512)', 4.184632062911987),\n",
       " ('CoLA and SST-2 LoRA (Shuffled, req_size=512)', 4.053811311721802),\n",
       " ('CoLA and SST-2 LoRA (Shuffled, req_size=512)', 4.0926079750061035),\n",
       " ('CoLA and SST-2 LoRA (Shuffled, req_size=512)', 4.058788061141968),\n",
       " ('CoLA and SST-2 LoRA (Shuffled, req_size=512)', 4.068758010864258),\n",
       " ('CoLA and SST-2 LoRA (Shuffled, req_size=512)', 4.054234743118286),\n",
       " ('CoLA and SST-2 LoRA (Shuffled, req_size=512)', 4.07751989364624),\n",
       " ('CoLA and SST-2 LoRA (Shuffled, req_size=1024)', 3.9444589614868164),\n",
       " ('CoLA and SST-2 LoRA (Shuffled, req_size=1024)', 3.9041101932525635),\n",
       " ('CoLA and SST-2 LoRA (Shuffled, req_size=1024)', 3.914973020553589),\n",
       " ('CoLA and SST-2 LoRA (Shuffled, req_size=1024)', 3.932121753692627),\n",
       " ('CoLA and SST-2 LoRA (Shuffled, req_size=1024)', 3.8935983180999756),\n",
       " ('CoLA and SST-2 LoRA (Shuffled, req_size=1024)', 3.9076220989227295),\n",
       " ('CoLA and SST-2 LoRA (Shuffled, req_size=1024)', 3.911134958267212)]"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "measurements"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "721c20bf-049d-4473-a1b8-4707d1b7806b",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame(measurements, columns=['type', 'duration_s'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "e6c0b0d0-ec14-4751-86a5-94e6fc9ad553",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>duration_s</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>type</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>CoLA LoRA</th>\n",
       "      <td>1.557595</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>CoLA and SST-2 LoRA</th>\n",
       "      <td>3.808635</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>CoLA and SST-2 LoRA (Shuffled, req_size=1024)</th>\n",
       "      <td>3.915431</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>CoLA and SST-2 LoRA (Shuffled, req_size=256)</th>\n",
       "      <td>4.022381</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>CoLA and SST-2 LoRA (Shuffled, req_size=512)</th>\n",
       "      <td>4.084336</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>CoLA and SST-2 LoRA (Shuffled, req_size=64)</th>\n",
       "      <td>4.817768</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SST-2 LoRA</th>\n",
       "      <td>2.305841</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Standalone SST-2</th>\n",
       "      <td>2.350065</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               duration_s\n",
       "type                                                     \n",
       "CoLA LoRA                                        1.557595\n",
       "CoLA and SST-2 LoRA                              3.808635\n",
       "CoLA and SST-2 LoRA (Shuffled, req_size=1024)    3.915431\n",
       "CoLA and SST-2 LoRA (Shuffled, req_size=256)     4.022381\n",
       "CoLA and SST-2 LoRA (Shuffled, req_size=512)     4.084336\n",
       "CoLA and SST-2 LoRA (Shuffled, req_size=64)      4.817768\n",
       "SST-2 LoRA                                       2.305841\n",
       "Standalone SST-2                                 2.350065"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.groupby('type').mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "3a49b1d5-0a2b-4a33-ab49-c0cc6da9343b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "alt.LayerChart(...)"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_bs = df[df.type.str.contains('req')]\n",
    "df_bs['type'] = df_bs['type'].str.extract('size=(\\d+)').astype(int)\n",
    "base = alt.Chart(df_bs, width=400).mark_bar(color='orange').encode(\n",
    "    x=alt.X('type:O'), \n",
    "    y=alt.Y('mean(duration_s):Q', scale=alt.Scale(zero=True)))\n",
    "error = base.mark_errorbar(extent='stdev').encode(y='duration_s:Q')\n",
    "base + error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "b2ac4c90-2861-4370-9908-d19822ce39f1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2.350065435682024, 0.1147209235600064, 4.881605499921438)"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tm = df.groupby('type').mean().reset_index()\n",
    "tm = {row.type: row.duration_s for _, row in tm.iterrows()}\n",
    "\n",
    "sst2_lora_multi = tm['CoLA and SST-2 LoRA (Shuffled, req_size=256)'] - tm['CoLA LoRA']\n",
    "sst2_standalone = tm['Standalone SST-2']\n",
    "overhead_s = sst2_lora_multi - sst2_standalone\n",
    "overhead_fraction = overhead_s / sst2_standalone\n",
    "sst2_standalone, overhead_s, overhead_fraction * 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "9c632003-f253-4cd3-98d2-918a61246bc6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "alt.Chart(...)"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import altair as alt\n",
    "import pandas as pd\n",
    "df = pd.DataFrame(data={\n",
    "    'scenario': ['Standalone', 'Multitask LoRA'],\n",
    "    'time_s': [sst2_standalone, sst2_lora_multi]\n",
    "})\n",
    "alt.Chart(df).mark_bar(color='orange').encode(\n",
    "    x=alt.X('scenario:O', sort=None), \n",
    "    y=alt.Y('time_s:Q', scale=alt.Scale(zero=False))).properties(width=200)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "74e0f0a7-0408-4f56-bb57-168646ac5060",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:sagemaker:Deleting model with name: lora-2024-03-31-20-47-23-961\n",
      "INFO:sagemaker:Deleting endpoint configuration with name: lora-2024-03-31-20-47-23-961\n",
      "INFO:sagemaker:Deleting endpoint with name: lora-2024-03-31-20-47-23-961\n"
     ]
    }
   ],
   "source": [
    "sst2_cola_lora_predictor.delete_model()\n",
    "sst2_cola_lora_predictor.delete_endpoint()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "03ead672-0f09-4b8d-9ddc-ca3f7a7f3373",
   "metadata": {},
   "source": [
    "g4dn.xl,roberta-base\n",
    "```\n",
    "2024-03-30T12:33:35,918 [INFO ] W-9000-model_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 2020\n",
    "2024-03-30T12:33:35,918 [INFO ] W-9000-model_1.0 TS_METRICS - WorkerThreadTime.Milliseconds:0.0|#Level:Host|#hostname:container-0.local,timestamp:1711802015\n",
    "2024-03-30T12:33:35,993 [INFO ] epollEventLoopGroup-3-1 TS_METRICS - ts_inference_requests_total.Count:1.0|#model_name:model,model_version:default|#hostname:container-0.local,timestamp:1711802015\n",
    "2024-03-30T12:33:35,993 [INFO ] W-9000-model_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req.cmd PREDICT to backend at: 1711802015993\n",
    "2024-03-30T12:33:35,994 [INFO ] W-9000-model_1.0-stdout MODEL_LOG - Backend received inference at: 1711802015\n",
    "2024-03-30T12:33:35,995 [INFO ] W-9000-model_1.0-stdout MODEL_LOG - Running inference for task: sst2\n",
    "2024-03-30T12:33:35,995 [INFO ] W-9000-model_1.0-stdout MODEL_LOG - Removing adapter cola.\n",
    "2024-03-30T12:33:35,996 [INFO ] W-9000-model_1.0-stdout MODEL_LOG - Installing adapter sst2.\n",
    "2024-03-30T12:33:35,998 [INFO ] W-9000-model_1.0-stdout MODEL_LOG - Changing adapter (remove and install) from cola to sst2 took  2.95 ms.\n",
    "2024-03-30T12:33:36,984 [INFO ] W-9000-model_1.0-stdout MODEL_LOG - Running inference for task: cola\n",
    "2024-03-30T12:33:36,984 [INFO ] W-9000-model_1.0-stdout MODEL_LOG - Removing adapter sst2.\n",
    "2024-03-30T12:33:36,986 [INFO ] W-9000-model_1.0-stdout MODEL_LOG - Installing adapter cola.\n",
    "2024-03-30T12:33:36,988 [INFO ] W-9000-model_1.0-stdout MODEL_LOG - Changing adapter (remove and install) from sst2 to cola took  3.10 ms.\n",
    "2024-03-30T12:33:37,611 [INFO ] W-9000-model_1.0-stdout MODEL_LOG - Inference call returns 891 predictions.\n",
    "2024-03-30T12:33:37,612 [INFO ] W-9000-model_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - result=[METRICS]PredictionTime.Milliseconds:1618.36|#ModelName:model,Level:Model|#hostname:container-0.local,1711802017,3f4375be-834f-4767-86aa-7d0cdd8cadb3, pattern=[METRICS]\n",
    "2024-03-30T12:33:37,612 [INFO ] W-9000-model_1.0-stdout MODEL_METRICS - PredictionTime.ms:1618.36|#ModelName:model,Level:Model|#hostname:container-0.local,requestID:3f4375be-834f-4767-86aa-7d0cdd8cadb3,timestamp:1711802017\n",
    "2024-03-30T12:33:37,613 [INFO ] W-9000-model_1.0 ACCESS_LOG - /169.254.178.2:39592 \"POST /invocations HTTP/1.1\" 200 1620\n",
    "2024-03-30T12:33:37,613 [INFO ] W-9000-model_1.0 TS_METRICS - Requests2XX.Count:1.0|#Level:Host|#hostname:container-0.local,timestamp:1711802017\n",
    "2024-03-30T12:33:37,613 [INFO ] W-9000-model_1.0 TS_METRICS - ts_inference_latency_microseconds.Microseconds:1619743.598|#model_name:model,model_version:default|#hostname:container-0.local,timestamp:1711802017\n",
    "2024-03-30T12:33:37,613 [INFO ] W-9000-model_1.0 TS_METRICS - ts_queue_latency_microseconds.Microseconds:61.408|#model_name:model,model_version:default|#hostname:container-0.local,timestamp:1711802017\n",
    "2024-03-30T12:33:37,613 [INFO ] W-9000-model_1.0 TS_METRICS - QueueTime.Milliseconds:0.0|#Level:Host|#hostname:container-0.local,timestamp:1711802017\n",
    "2024-03-30T12:33:37,613 [INFO ] W-9000-model_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1619\n",
    "2024-03-30T12:33:37,613 [INFO ] W-9000-model_1.0 TS_METRICS - WorkerThreadTime.Milliseconds:1.0|#Level:Host|#hostname:container-0.local,timestamp:1711802017\n",
    "2024-03-30T12:33:37,689 [INFO ] epollEventLoopGroup-3-1 TS_METRICS - ts_inference_requests_total.Count:1.0|#model_name:model,model_version:default|#hostname:container-0.local,timestamp:1711802017\n",
    "2024-03-30T12:33:37,690 [INFO ] W-9000-model_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req.cmd PREDICT to backend at: 1711802017690\n",
    "2024-03-30T12:33:37,690 [INFO ] W-9000-model_1.0-stdout MODEL_LOG - Backend received inference at: 1711802017\n",
    "2024-03-30T12:33:37,692 [INFO ] W-9000-model_1.0-stdout MODEL_LOG - Running inference for task: sst2\n",
    "2024-03-30T12:33:37,692 [INFO ] W-9000-model_1.0-stdout MODEL_LOG - Removing adapter cola.\n",
    "2024-03-30T12:33:37,693 [INFO ] W-9000-model_1.0-stdout MODEL_LOG - Installing adapter sst2.\n",
    "2024-03-30T12:33:37,695 [INFO ] W-9000-model_1.0-stdout MODEL_LOG - Changing adapter (remove and install) from cola to sst2 took  3.08 ms.\n",
    "2024-03-30T12:33:38,863 [INFO ] pool-2-thread-2 ACCESS_LOG - /169.254.178.2:57236 \"GET /ping HTTP/1.1\" 200 0\n",
    "2024-03-30T12:33:38,864 [INFO ] pool-2-thread-2 TS_METRICS - Requests2XX.Count:1.0|#Level:Host|#hostname:container-0.local,timestamp:1711802018\n",
    "2024-03-30T12:33:38,874 [INFO ] W-9000-model_1.0-stdout MODEL_LOG - Running inference for task: cola\n",
    "2024-03-30T12:33:38,875 [INFO ] W-9000-model_1.0-stdout MODEL_LOG - Removing adapter sst2.\n",
    "2024-03-30T12:33:38,876 [INFO ] W-9000-model_1.0-stdout MODEL_LOG - Installing adapter cola.\n",
    "2024-03-30T12:33:38,878 [INFO ] W-9000-model_1.0-stdout MODEL_LOG - Changing adapter (remove and install) from sst2 to cola took  3.47 ms.\n",
    "2024-03-30T12:33:39,716 [INFO ] W-9000-model_1.0-stdout MODEL_LOG - Inference call returns 1024 predictions.\n",
    "2024-03-30T12:33:39,717 [INFO ] W-9000-model_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - result=[METRICS]PredictionTime.Milliseconds:2026.38|#ModelName:model,Level:Model|#hostname:container-0.local,1711802019,5c86f56c-fe59-4cc4-ba9d-bd8ed4049bb2, pattern=[METRICS]\n",
    "2024-03-30T12:33:39,717 [INFO ] W-9000-model_1.0-stdout MODEL_METRICS - PredictionTime.ms:2026.38|#ModelName:model,Level:Model|#hostname:container-0.local,requestID:5c86f56c-fe59-4cc4-ba9d-bd8ed4049bb2,timestamp:1711802019\n",
    "2024-03-30T12:33:39,717 [INFO ] W-9000-model_1.0 ACCESS_LOG - /169.254.178.2:39592 \"POST /invocations HTTP/1.1\" 200 2028\n",
    "2024-03-30T12:33:39,717 [INFO ] W-9000-model_1.0 TS_METRICS - Requests2XX.Count:1.0|#Level:Host|#hostname:container-0.local,timestamp:1711802019\n",
    "2024-03-30T12:33:39,717 [INFO ] W-9000-model_1.0 TS_METRICS - ts_inference_latency_microseconds.Microseconds:2027617.502|#model_name:model,model_version:default|#hostname:container-0.local,timestamp:1711802019\n",
    "2024-03-30T12:33:39,717 [INFO ] W-9000-model_1.0 TS_METRICS - ts_queue_latency_microseconds.Microseconds:87.709|#model_name:model,model_version:default|#hostname:container-0.local,timestamp:1711802019\n",
    "2024-03-30T12:33:39,717 [INFO ] W-9000-model_1.0 TS_METRICS - QueueTime.Milliseconds:0.0|#Level:Host|#hostname:container-0.local,timestamp:1711802019\n",
    "2024-03-30T12:33:39,717 [INFO ] W-9000-model_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 2027\n",
    "2024-03-30T12:33:39,717 [INFO ] W-9000-model_1.0 TS_METRICS - WorkerThreadTime.Milliseconds:0.0|#Level:Host|#hostname:container-0.local,timestamp:1711802019\n",
    "2024-03-30T12:33:39,854 [INFO ] epollEventLoopGroup-3-1 TS_METRICS - ts_inference_requests_total.Count:1.0|#model_name:model,model_version:default|#hostname:container-0.local,timestamp:1711802019\n",
    "2024-03-30T12:33:39,854 [INFO ] W-9000-model_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req.cmd PREDICT to backend at: 1711802019854\n",
    "2024-03-30T12:33:39,854 [INFO ] W-9000-model_1.0-stdout MODEL_LOG - Backend received inference at: 1711802019\n",
    "2024-03-30T12:33:39,856 [INFO ] W-9000-model_1.0-stdout MODEL_LOG - Running inference for task: sst2\n",
    "2024-03-30T12:33:39,856 [INFO ] W-9000-model_1.0-stdout MODEL_LOG - Removing adapter cola.\n",
    "2024-03-30T12:33:39,857 [INFO ] W-9000-model_1.0-stdout MODEL_LOG - Installing adapter sst2.\n",
    "2024-03-30T12:33:39,859 [INFO ] W-9000-model_1.0-stdout MODEL_LOG - Changing adapter (remove and install) from cola to sst2 took  2.99 ms.\n",
    "2024-03-30T12:33:40,846 [INFO ] W-9000-model_1.0-stdout MODEL_LOG - Running inference for task: cola\n",
    "2024-03-30T12:33:40,846 [INFO ] W-9000-model_1.0-stdout MODEL_LOG - Removing adapter sst2.\n",
    "2024-03-30T12:33:40,847 [INFO ] W-9000-model_1.0-stdout MODEL_LOG - Installing adapter cola.\n",
    "2024-03-30T12:33:40,849 [INFO ] W-9000-model_1.0-stdout MODEL_LOG - Changing adapter (remove and install) from sst2 to cola took  2.95 ms.\n",
    "2024-03-30T12:33:41,466 [INFO ] W-9000-model_1.0-stdout MODEL_LOG - Inference call returns 891 predictions.\n",
    "2024-03-30T12:33:41,468 [INFO ] W-9000-model_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - result=[METRICS]PredictionTime.Milliseconds:1613.48|#ModelName:model,Level:Model|#hostname:container-0.local,1711802021,62e3a39c-2596-4cab-b7d5-226df9568251, pattern=[METRICS]\n",
    "2024-03-30T12:33:41,468 [INFO ] W-9000-model_1.0-stdout MODEL_METRICS - PredictionTime.ms:1613.48|#ModelName:model,Level:Model|#hostname:container-0.local,requestID:62e3a39c-2596-4cab-b7d5-226df9568251,timestamp:1711802021\n",
    "2024-03-30T12:33:41,468 [INFO ] W-9000-model_1.0 ACCESS_LOG - /169.254.178.2:39592 \"POST /invocations HTTP/1.1\" 200 1615\n",
    "2024-03-30T12:33:41,468 [INFO ] W-9000-model_1.0 TS_METRICS - Requests2XX.Count:1.0|#Level:Host|#hostname:container-0.local,timestamp:1711802021\n",
    "2024-03-30T12:33:41,468 [INFO ] W-9000-model_1.0 TS_METRICS - ts_inference_latency_microseconds.Microseconds:1614578.676|#model_name:model,model_version:default|#hostname:container-0.local,timestamp:1711802021\n",
    "2024-03-30T12:33:41,468 [INFO ] W-9000-model_1.0 TS_METRICS - ts_queue_latency_microseconds.Microseconds:71.509|#model_name:model,model_version:default|#hostname:container-0.local,timestamp:1711802021\n",
    "2024-03-30T12:33:41,468 [INFO ] W-9000-model_1.0 TS_METRICS - QueueTime.Milliseconds:0.0|#Level:Host|#hostname:container-0.local,timestamp:1711802021\n",
    "2024-03-30T12:33:41,468 [INFO ] W-9000-model_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1614\n",
    "2024-03-30T12:33:41,468 [INFO ] W-9000-model_1.0 TS_METRICS - WorkerThreadTime.Milliseconds:0.0|#Level:Host|#hostname:container-0.local,timestamp:1711802021\n",
    "2024-03-30T12:33:41,582 [INFO ] epollEventLoopGroup-3-1 TS_METRICS - ts_inference_requests_total.Count:1.0|#model_name:model,model_version:default|#hostname:container-0.local,timestamp:1711802021\n",
    "2024-03-30T12:33:41,582 [INFO ] W-9000-model_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req.cmd PREDICT to backend at: 1711802021582\n",
    "2024-03-30T12:33:41,583 [INFO ] W-9000-model_1.0-stdout MODEL_LOG - Backend received inference at: 1711802021\n",
    "2024-03-30T12:33:41,584 [INFO ] W-9000-model_1.0-stdout MODEL_LOG - Running inference for task: sst2\n",
    "2024-03-30T12:33:41,584 [INFO ] W-9000-model_1.0-stdout MODEL_LOG - Removing adapter cola.\n",
    "2024-03-30T12:33:41,585 [INFO ] W-9000-model_1.0-stdout MODEL_LOG - Installing adapter sst2.\n",
    "2024-03-30T12:33:41,587 [INFO ] W-9000-model_1.0-stdout MODEL_LOG - Changing adapter (remove and install) from cola to sst2 took  3.02 ms.\n",
    "2024-03-30T12:33:42,766 [INFO ] W-9000-model_1.0-stdout MODEL_LOG - Running inference for task: cola\n",
    "2024-03-30T12:33:42,766 [INFO ] W-9000-model_1.0-stdout MODEL_LOG - Removing adapter sst2.\n",
    "2024-03-30T12:33:42,767 [INFO ] W-9000-model_1.0-stdout MODEL_LOG - Installing adapter cola.\n",
    "2024-03-30T12:33:42,769 [INFO ] W-9000-model_1.0-stdout MODEL_LOG - Changing adapter (remove and install) from sst2 to cola took  2.99 ms.\n",
    "2024-03-30T12:33:43,605 [INFO ] W-9000-model_1.0-stdout MODEL_LOG - Inference call returns 1024 predictions.\n",
    "2024-03-30T12:33:43,606 [INFO ] W-9000-model_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - result=[METRICS]PredictionTime.Milliseconds:2023.38|#ModelName:model,Level:Model|#hostname:container-0.local,1711802023,025adc14-11d9-4953-9228-070763ef21f6, pattern=[METRICS]\n",
    "2024-03-30T12:33:43,607 [INFO ] W-9000-model_1.0-stdout MODEL_METRICS - PredictionTime.ms:2023.38|#ModelName:model,Level:Model|#hostname:container-0.local,requestID:025adc14-11d9-4953-9228-070763ef21f6,timestamp:1711802023\n",
    "2024-03-30T12:33:43,607 [INFO ] W-9000-model_1.0 ACCESS_LOG - /169.254.178.2:39592 \"POST /invocations HTTP/1.1\" 200 2025\n",
    "2024-03-30T12:33:43,607 [INFO ] W-9000-model_1.0 TS_METRICS - Requests2XX.Count:1.0|#Level:Host|#hostname:container-0.local,timestamp:1711802023\n",
    "2024-03-30T12:33:43,607 [INFO ] W-9000-model_1.0 TS_METRICS - ts_inference_latency_microseconds.Microseconds:2024551.595|#model_name:model,model_version:default|#hostname:container-0.local,timestamp:1711802023\n",
    "2024-03-30T12:33:43,607 [INFO ] W-9000-model_1.0 TS_METRICS - ts_queue_latency_microseconds.Microseconds:77.242|#model_name:model,model_version:default|#hostname:container-0.local,timestamp:1711802023\n",
    "2024-03-30T12:33:43,607 [INFO ] W-9000-model_1.0 TS_METRICS - QueueTime.Milliseconds:0.0|#Level:Host|#hostname:container-0.local,timestamp:1711802023\n",
    "2024-03-30T12:33:43,607 [INFO ] W-9000-model_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 2024\n",
    "2024-03-30T12:33:43,607 [INFO ] W-9000-model_1.0 TS_METRICS - WorkerThreadTime.Milliseconds:1.0|#Level:Host|#hostname:container-0.local,timestamp:1711802023\n",
    "2024-03-30T12:33:43,694 [INFO ] epollEventLoopGroup-3-1 TS_METRICS - ts_inference_requests_total.Count:1.0|#model_name:model,model_version:default|#hostname:container-0.local,timestamp:1711802023\n",
    "2024-03-30T12:33:43,694 [INFO ] W-9000-model_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req.cmd PREDICT to backend at: 1711802023694\n",
    "2024-03-30T12:33:43,695 [INFO ] W-9000-model_1.0-stdout MODEL_LOG - Backend received inference at: 1711802023\n",
    "2024-03-30T12:33:43,696 [INFO ] W-9000-model_1.0-stdout MODEL_LOG - Running inference for task: sst2\n",
    "2024-03-30T12:33:43,696 [INFO ] W-9000-model_1.0-stdout MODEL_LOG - Removing adapter cola.\n",
    "2024-03-30T12:33:43,697 [INFO ] W-9000-model_1.0-stdout MODEL_LOG - Installing adapter sst2.\n",
    "2024-03-30T12:33:43,699 [INFO ] W-9000-model_1.0-stdout MODEL_LOG - Changing adapter (remove and install) from cola to sst2 took  3.19 ms.\n",
    "2024-03-30T12:33:43,864 [INFO ] pool-2-thread-2 ACCESS_LOG - /169.254.178.2:57236 \"GET /ping HTTP/1.1\" 200 1\n",
    "2024-03-30T12:33:43,864 [INFO ] pool-2-thread-2 TS_METRICS - Requests2XX.Count:1.0|#Level:Host|#hostname:container-0.local,timestamp:1711802023\n",
    "2024-03-30T12:33:44,688 [INFO ] W-9000-model_1.0-stdout MODEL_LOG - Running inference for task: cola\n",
    "2024-03-30T12:33:44,688 [INFO ] W-9000-model_1.0-stdout MODEL_LOG - Removing adapter sst2.\n",
    "2024-03-30T12:33:44,689 [INFO ] W-9000-model_1.0-stdout MODEL_LOG - Installing adapter cola.\n",
    "2024-03-30T12:33:44,691 [INFO ] W-9000-model_1.0-stdout MODEL_LOG - Changing adapter (remove and install) from sst2 to cola took  3.11 ms.\n",
    "2024-03-30T12:33:45,310 [INFO ] W-9000-model_1.0-stdout MODEL_LOG - Inference call returns 891 predictions.\n",
    "2024-03-30T12:33:45,311 [INFO ] W-9000-model_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - result=[METRICS]PredictionTime.Milliseconds:1616.61|#ModelName:model,Level:Model|#hostname:container-0.local,1711802025,c60b8632-6396-41bf-9dc0-2cdfb17ea11f, pattern=[METRICS]\n",
    "2024-03-30T12:33:45,312 [INFO ] W-9000-model_1.0-stdout MODEL_METRICS - PredictionTime.ms:1616.61|#ModelName:model,Level:Model|#hostname:container-0.local,requestID:c60b8632-6396-41bf-9dc0-2cdfb17ea11f,timestamp:1711802025\n",
    "2024-03-30T12:33:45,312 [INFO ] W-9000-model_1.0 ACCESS_LOG - /169.254.178.2:39592 \"POST /invocations HTTP/1.1\" 200 1618\n",
    "2024-03-30T12:33:45,312 [INFO ] W-9000-model_1.0 TS_METRICS - Requests2XX.Count:1.0|#Level:Host|#hostname:container-0.local,timestamp:1711802025\n",
    "2024-03-30T12:33:45,312 [INFO ] W-9000-model_1.0 TS_METRICS - ts_inference_latency_microseconds.Microseconds:1617942.474|#model_name:model,model_version:default|#hostname:container-0.local,timestamp:1711802025\n",
    "2024-03-30T12:33:45,312 [INFO ] W-9000-model_1.0 TS_METRICS - ts_queue_latency_microseconds.Microseconds:73.046|#model_name:model,model_version:default|#hostname:container-0.local,timestamp:1711802025\n",
    "2024-03-30T12:33:45,312 [INFO ] W-9000-model_1.0 TS_METRICS - QueueTime.Milliseconds:0.0|#Level:Host|#hostname:container-0.local,timestamp:1711802025\n",
    "2024-03-30T12:33:45,312 [INFO ] W-9000-model_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1618\n",
    "2024-03-30T12:33:45,312 [INFO ] W-9000-model_1.0 TS_METRICS - WorkerThreadTime.Milliseconds:0.0|#Level:Host|#hostname:container-0.local,timestamp:1711802025\n",
    "2024-03-30T12:33:48,864 [INFO ] pool-2-thread-2 ACCESS_LOG - /169.254.178.2:39592 \"GET /ping HTTP/1.1\" 200 0\n",
    "2024-03-30T12:33:48,864 [INFO ] pool-2-thread-2 TS_METRICS - Requests2XX.Count:1.0|#Level:Host|#hostname:container-0.local,timestamp:1711802028\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d65b2f95-f235-4d8a-9a3e-7e3d7001d149",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "availableInstances": [
   {
    "_defaultOrder": 0,
    "_isFastLaunch": true,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 4,
    "name": "ml.t3.medium",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 1,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 8,
    "name": "ml.t3.large",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 2,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.t3.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 3,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.t3.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 4,
    "_isFastLaunch": true,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 8,
    "name": "ml.m5.large",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 5,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.m5.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 6,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.m5.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 7,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 64,
    "name": "ml.m5.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 8,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 128,
    "name": "ml.m5.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 9,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 192,
    "name": "ml.m5.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 10,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 256,
    "name": "ml.m5.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 11,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 384,
    "name": "ml.m5.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 12,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 8,
    "name": "ml.m5d.large",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 13,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.m5d.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 14,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.m5d.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 15,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 64,
    "name": "ml.m5d.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 16,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 128,
    "name": "ml.m5d.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 17,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 192,
    "name": "ml.m5d.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 18,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 256,
    "name": "ml.m5d.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 19,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 384,
    "name": "ml.m5d.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 20,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": true,
    "memoryGiB": 0,
    "name": "ml.geospatial.interactive",
    "supportedImageNames": [
     "sagemaker-geospatial-v1-0"
    ],
    "vcpuNum": 0
   },
   {
    "_defaultOrder": 21,
    "_isFastLaunch": true,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 4,
    "name": "ml.c5.large",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 22,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 8,
    "name": "ml.c5.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 23,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.c5.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 24,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.c5.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 25,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 72,
    "name": "ml.c5.9xlarge",
    "vcpuNum": 36
   },
   {
    "_defaultOrder": 26,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 96,
    "name": "ml.c5.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 27,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 144,
    "name": "ml.c5.18xlarge",
    "vcpuNum": 72
   },
   {
    "_defaultOrder": 28,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 192,
    "name": "ml.c5.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 29,
    "_isFastLaunch": true,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.g4dn.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 30,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.g4dn.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 31,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 64,
    "name": "ml.g4dn.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 32,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 128,
    "name": "ml.g4dn.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 33,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 4,
    "hideHardwareSpecs": false,
    "memoryGiB": 192,
    "name": "ml.g4dn.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 34,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 256,
    "name": "ml.g4dn.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 35,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 61,
    "name": "ml.p3.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 36,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 4,
    "hideHardwareSpecs": false,
    "memoryGiB": 244,
    "name": "ml.p3.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 37,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 8,
    "hideHardwareSpecs": false,
    "memoryGiB": 488,
    "name": "ml.p3.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 38,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 8,
    "hideHardwareSpecs": false,
    "memoryGiB": 768,
    "name": "ml.p3dn.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 39,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.r5.large",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 40,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.r5.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 41,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 64,
    "name": "ml.r5.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 42,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 128,
    "name": "ml.r5.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 43,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 256,
    "name": "ml.r5.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 44,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 384,
    "name": "ml.r5.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 45,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 512,
    "name": "ml.r5.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 46,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 768,
    "name": "ml.r5.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 47,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.g5.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 48,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.g5.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 49,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 64,
    "name": "ml.g5.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 50,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 128,
    "name": "ml.g5.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 51,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 256,
    "name": "ml.g5.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 52,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 4,
    "hideHardwareSpecs": false,
    "memoryGiB": 192,
    "name": "ml.g5.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 53,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 4,
    "hideHardwareSpecs": false,
    "memoryGiB": 384,
    "name": "ml.g5.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 54,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 8,
    "hideHardwareSpecs": false,
    "memoryGiB": 768,
    "name": "ml.g5.48xlarge",
    "vcpuNum": 192
   }
  ],
  "instance_type": "ml.t3.medium",
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
